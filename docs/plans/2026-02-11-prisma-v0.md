# Prisma v0 Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Get a running v0 of Prisma that demonstrates the full flow â€” user describes a decision in Claude Code â†’ Prisma asks follow-ups â†’ generates an interactive dark-mode HTML dashboard with Monte Carlo simulation, causal graph, Taleb classification, sensitivity analysis, and scenario comparison that opens in the browser.

**Architecture:** Claude Code is the orchestrator. CLAUDE.md instructs Opus 4.6 to act as a decision scientist. The user has a conversation in the terminal. Opus 4.6 generates a self-contained HTML/JS file with all simulation engines embedded. The file opens in the browser. All interactivity runs client-side.

**Tech Stack:** Vanilla JavaScript (engines + interactivity), Canvas API (Monte Carlo animation), Plotly.js via CDN (charts), Python + pandas (Tier 2 data processing), HTML/CSS (dark mode cinematic dashboard)

---

## Task 1: Initialize GitHub Repo & Folder Structure

**Files:**
- Create: `prisma/` repo structure (all directories)
- Create: `LICENSE`
- Create: `README.md` (minimal placeholder)
- Create: `.gitignore`

**Step 1: Initialize git repo and create folder structure**

```bash
cd /Users/muzaffer/projects/ClaudeCode_Hackathon
git init
mkdir -p engines templates data examples/delivery-company docs/plans skills
```

**Step 2: Create LICENSE (MIT)**

Create `LICENSE` with MIT license text, copyright 2026 Muz.

**Step 3: Create .gitignore**

```
.DS_Store
node_modules/
__pycache__/
*.pyc
.env
output/
*.swp
```

**Step 4: Create minimal README.md**

```markdown
# PRISMA

**1,000 futures. One decision.**

Prisma is a decision intelligence engine that lets you see the consequences of your choices before committing. Powered by Monte Carlo simulation, Markov chains, and the Taleb fragility framework â€” all accessible through a conversation.

> Built for the "Built with Opus 4.6" Claude Code Hackathon, Feb 2026.

## Quick Start

1. Clone this repo
2. Open the folder with Claude Code: `claude`
3. Start talking: "What decision are you facing?"

## How It Works

You describe a decision under uncertainty. Prisma's crew goes to work:

- **Carlo** â€” The Simulator. Runs 1,000 randomized futures.
- **Markov** â€” The Oracle. Sees how things change through time.
- **Nassim** â€” The Judge. Classifies your options as fragile, robust, or antifragile.

The result: an interactive dashboard where you explore scenarios, drag sliders, and see the full spectrum of possible outcomes â€” so you decide with confidence, not anxiety.

## License

MIT
```

**Step 5: Move existing docs into place**

```bash
cp CLAUDE.md CLAUDE.md  # already in root, good
cp PRODUCT_VISION.md docs/PRODUCT_VISION.md
cp SCOPE.md docs/SCOPE.md
```

**Step 6: Initial commit**

```bash
git add -A
git commit -m "init: Prisma project structure, vision docs, CLAUDE.md"
```

---

## Task 2: Build the Monte Carlo Engine (`engines/carlo.js`)

**Files:**
- Create: `engines/carlo.js`

**Step 1: Write carlo.js with core functions**

The Monte Carlo engine needs four functions:

```javascript
// engines/carlo.js â€” Carlo: The Simulator

/**
 * Sample a random value from a distribution
 * @param {Object} variable - {value, min, max, distribution}
 * @returns {number} sampled value
 */
function sampleFromDistribution(variable) {
  // Support: normal, uniform, right_skewed, left_skewed, fixed
}

/**
 * Run a single simulation through the causal graph
 * @param {Object} model - {variables, edges, scenario}
 * @returns {Object} outcome for this single run
 */
function runSingleSimulation(model) {
  // Sample all independent variables
  // Propagate through causal edges
  // Calculate final outcome metrics (profit, cost, satisfaction, etc.)
}

/**
 * Run Monte Carlo simulation â€” 1,000 iterations
 * @param {Object} model - full model with variables, edges, scenarios
 * @param {number} iterations - default 1000
 * @returns {Object} results per scenario {scenarioId: [outcomes]}
 */
function runCarlo(model, iterations = 1000) {
  // For each scenario, run iterations simulations
  // Return array of outcome objects per scenario
}

/**
 * Calculate summary statistics from Monte Carlo results
 * @param {Array} outcomes - array of 1000 outcome values
 * @returns {Object} {median, mean, p10, p90, min, max, percentPositive}
 */
function summarizeResults(outcomes) {
  // Sort, calculate percentiles, median, mean
}
```

Key implementation details:
- `sampleFromDistribution`: Use Box-Muller transform for normal distribution. Use beta distribution approximation for skewed. Uniform is just `min + Math.random() * (max - min)`.
- `runSingleSimulation`: Walk the causal graph topologically â€” sample root variables first, then compute dependent variables using the edge relationships.
- `runCarlo`: Simple loop calling `runSingleSimulation` 1,000 times per scenario, collecting outcomes.
- All functions must be pure (no side effects, no DOM access) so they work both standalone and embedded in HTML.

**Step 2: Verify engine works**

Create a quick test HTML file (`test-carlo.html`) that loads the engine, runs a simple 2-scenario simulation, and logs results to console. Open in browser, check console.

**Step 3: Commit**

```bash
git add engines/carlo.js test-carlo.html
git commit -m "feat: Carlo engine â€” Monte Carlo simulation with distribution sampling"
```

---

## Task 3: Build the Nassim Engine (`engines/nassim.js`)

**Files:**
- Create: `engines/nassim.js`

**Step 1: Write nassim.js with Taleb classification + sensitivity**

```javascript
// engines/nassim.js â€” Nassim: The Judge

/**
 * Classify a scenario's outcomes using the Taleb framework
 * @param {Array} outcomes - array of 1000 numeric outcomes
 * @returns {Object} {classification, confidence, reasoning}
 *
 * FRAGILE: >40% negative OR worst 10% catastrophic (>3x median loss)
 * ROBUST: >65% positive AND worst 10% manageable (<2x median)
 * ANTIFRAGILE: performs better under doubled uncertainty
 */
function classifyTaleb(outcomes, highVarianceOutcomes = null) {
  // Calculate % positive, % negative
  // Check tail behavior (p10)
  // If highVarianceOutcomes provided, compare performance
  // Return classification + reasoning string
}

/**
 * Run sensitivity analysis â€” which variables matter most?
 * @param {Object} model - full model
 * @param {Function} runCarlo - reference to Carlo's simulation function
 * @param {number} iterations - per sensitivity run (can be lower, 200-500)
 * @returns {Array} [{variableId, variableLabel, impactLow, impactHigh, totalSwing}] sorted by totalSwing desc
 */
function runSensitivity(model, runCarlo, iterations = 500) {
  // For each variable:
  //   1. Hold it at min, run Carlo â†’ get median outcome
  //   2. Hold it at max, run Carlo â†’ get median outcome
  //   3. totalSwing = abs(medianAtMax - medianAtMin)
  // Sort by totalSwing descending
  // Return top N most impactful variables
}
```

**Step 2: Verify with test**

Add Nassim tests to `test-carlo.html` â€” feed Carlo's output into Nassim, check that classification logic works. Console log the Taleb classification and sensitivity ranking.

**Step 3: Commit**

```bash
git add engines/nassim.js
git commit -m "feat: Nassim engine â€” Taleb classification + sensitivity analysis"
```

---

## Task 4: Build the Markov Engine (`engines/markov.js`)

**Files:**
- Create: `engines/markov.js`

**Step 1: Write markov.js with state transition logic**

```javascript
// engines/markov.js â€” Markov: The Oracle

/**
 * Define state transition matrix
 * @param {Object} stateConfig - {states: [...], transitions: {fromState: {toState: probability}}}
 * @returns {Object} validated transition matrix
 */
function createTransitionMatrix(stateConfig) {
  // Validate all rows sum to 1.0
  // Return structured matrix
}

/**
 * Run a single Markov chain forward N steps
 * @param {string} initialState
 * @param {Object} transitionMatrix
 * @param {number} steps - months to simulate
 * @returns {Array} state at each step [{month, state}]
 */
function walkChain(initialState, transitionMatrix, steps = 6) {
  // At each step, sample next state based on current state's probabilities
  // Return path through states
}

/**
 * Run Markov inside Monte Carlo â€” 1,000 paths through time
 * @param {Object} markovConfig - states + transitions per scenario
 * @param {number} iterations
 * @param {number} months
 * @returns {Object} {scenarioId: {month: {state: count}}} distribution of states at each time step
 */
function runMarkovMonteCarlo(markovConfig, iterations = 1000, months = 6) {
  // For each iteration: walk the chain, record state at each month
  // Aggregate: at month N, X% are in state A, Y% in state B
  // Return aggregated distributions per month per scenario
}
```

**Step 2: Verify with test**

Add to test HTML â€” simulate a driver reliability Markov chain, check that state distributions evolve sensibly over 6 months.

**Step 3: Commit**

```bash
git add engines/markov.js
git commit -m "feat: Markov engine â€” state transitions + time evolution"
```

---

## Task 5: Build the Dashboard Template (`templates/dashboard.html`)

This is the big one. A self-contained HTML file that serves as the BASE template. Opus 4.6 will customize it with specific data, but the structure, styling, and engine code are pre-built.

**Files:**
- Create: `templates/dashboard.html`
- Create: `templates/styles.css` (inlined into HTML but developed separately for clarity)

**Step 1: Create the HTML shell with dark mode styling**

The dashboard has these sections (top to bottom):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HEADER: "PRISMA" + decision summary     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SECTION 1: Causal Graph (Canvas)        â”‚
â”‚ Animated network of variables           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SECTION 2: Monte Carlo (Canvas)         â”‚
â”‚ 1,000 glowing dots forming distribution â”‚
â”‚ Side-by-side for each scenario          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SECTION 3: Nassim's Verdict             â”‚
â”‚ FRAGILE / ROBUST / ANTIFRAGILE badges   â”‚
â”‚ Per scenario with confidence bars       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SECTION 4: Sensitivity (Plotly)         â”‚
â”‚ Tornado diagram â€” what matters most     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SECTION 5: Markov Timeline (Canvas)     â”‚
â”‚ Two paths diverging over 6 months       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SECTION 6: Interactive Sliders          â”‚
â”‚ Drag to change variables, re-run sim    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SECTION 7: Recommendation               â”‚
â”‚ WHAT TO DO / WATCH / CHANGE YOUR MIND   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ FOOTER: "Prisma â€” See the full spectrum"â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

CSS Requirements (from CLAUDE.md):
- Background: `#0a0a0f`
- Text: `#e0e0e0` (primary), `#888` (secondary)
- Accent: `#4fc3f7` (electric blue)
- Robust/positive: `#4caf50` (green)
- Fragile/negative: `#ef5350` (red)
- Uncertain: `#ffa726` (amber)
- Antifragile: `#ab47bc` (purple)
- Font: `system-ui, -apple-system, sans-serif`
- Subtle glow effects using `box-shadow` and canvas `shadowBlur`
- Smooth CSS transitions on all interactive elements

**Step 2: Build the Causal Graph renderer (Canvas)**

Draw variables as glowing nodes, edges as animated lines with arrows. Feedback loops highlighted with pulsing red glow.

- Nodes positioned using a simple force-directed or predefined layout
- Edges drawn as bezier curves with arrowheads
- Feedback loops get a pulsing animation (CSS keyframes on canvas redraw)
- Node labels rendered on canvas

Input: the causal graph JSON from CLAUDE.md Step 3.

**Step 3: Build the Monte Carlo dot animation (Canvas)**

The hero visual. This needs to be impressive.

- Canvas element per scenario (or one wide canvas with columns)
- Each dot: small circle with `shadowBlur` for glow effect
- Animation: dots appear one by one (or in batches of 50) and drift to their position in the distribution
- X-axis: outcome value (profit/loss)
- Y-axis: slight random jitter so dots don't overlap
- Color: green if positive, red if negative, gradient in between
- After animation settles: overlay a translucent distribution curve

Animation sequence:
1. Canvas starts empty (dark)
2. "Carlo is running 1,000 futures..." text appears
3. Dots stream in over 2-3 seconds, scattering then clustering
4. Distribution curve fades in
5. Summary stats appear (median, p10, p90)

**Step 4: Build the Scenario Comparison view**

Side-by-side distributions using Plotly.js:
- One violin/histogram per scenario
- Color-coded by Taleb classification
- Median line marked
- Confidence band (p10-p90) shaded

```javascript
Plotly.newPlot('scenario-compare', [{
  type: 'violin',
  y: scenarioAOutcomes,
  name: 'Hire',
  line: {color: '#4caf50'}
}, {
  type: 'violin',
  y: scenarioBOutcomes,
  name: 'Restructure',
  line: {color: '#ffa726'}
}, {
  type: 'violin',
  y: scenarioCOutcomes,
  name: 'Do Nothing',
  line: {color: '#ef5350'}
}], {
  paper_bgcolor: '#0a0a0f',
  plot_bgcolor: '#0a0a0f',
  font: {color: '#e0e0e0'}
});
```

**Step 5: Build the Taleb Classification badges**

HTML/CSS badges that display:
```
[HIRE]           [RESTRUCTURE]    [DO NOTHING]
ðŸŸ¢ ROBUST        ðŸŸ¡ UNCERTAIN     ðŸ”´ FRAGILE
Works in 78%     Works in 52%     Fails in 74%
of futures       of futures       of futures
```

Styled as glowing cards with the classification color as border/glow.

**Step 6: Build the Sensitivity tornado diagram (Plotly)**

Horizontal bar chart:
- Each bar = one variable
- Bar extends left (impact when variable is at min) and right (impact at max)
- Sorted by total swing (biggest impact at top)
- Color: blue accent

```javascript
Plotly.newPlot('tornado', [{
  type: 'bar',
  orientation: 'h',
  y: variableLabels,
  x: impactValues,
  marker: {color: '#4fc3f7'}
}], {
  paper_bgcolor: '#0a0a0f',
  plot_bgcolor: '#0a0a0f',
  font: {color: '#e0e0e0'},
  title: 'What matters most?'
});
```

**Step 7: Build the Interactive Sliders**

For each key variable, render a range slider:
```html
<div class="slider-group">
  <label>Daily Deliveries: <span id="val-deliveries">80</span></label>
  <input type="range" min="40" max="150" value="80"
         oninput="updateVariable('daily_deliveries', this.value); rerunSimulation()">
</div>
```

On change: update the variable in the model, re-run Carlo (1,000 iterations â€” should be <100ms in browser), update all visualizations.

**Step 8: Build the Recommendation panel**

Three columns at the bottom:

```html
<div class="recommendation">
  <div class="rec-card">
    <h3>WHAT TO DO</h3>
    <p id="rec-action"><!-- filled by Opus 4.6 --></p>
  </div>
  <div class="rec-card">
    <h3>WHAT TO WATCH</h3>
    <p id="rec-watch"><!-- filled by Opus 4.6 --></p>
  </div>
  <div class="rec-card">
    <h3>WHEN TO CHANGE YOUR MIND</h3>
    <p id="rec-trigger"><!-- filled by Opus 4.6 --></p>
  </div>
</div>
```

**Step 9: Build the Markov Timeline visualization (Canvas)**

Two (or three) animated lines diverging over a 6-month timeline:
- X-axis: months 1-6
- Y-axis: business health / profit metric
- Each scenario is a band (p25-p75) with a median line
- Lines start close together and diverge over time
- Color-coded by scenario
- Animated: draws left to right over 2 seconds

**Step 10: Wire everything together**

The dashboard HTML has a `window.PRISMA_DATA` object at the top that contains all the model data. When the page loads:
1. Parse `PRISMA_DATA`
2. Run Carlo â†’ populate Monte Carlo visualization + scenario comparison
3. Run Nassim â†’ populate Taleb badges + tornado diagram
4. Run Markov (if data present) â†’ populate timeline
5. Wire sliders to re-run on change
6. Fill recommendation panel from data

```javascript
window.PRISMA_DATA = {
  title: "Should I hire new drivers?",
  variables: [...],
  edges: [...],
  scenarios: [...],
  feedbackLoops: [...],
  markovConfig: {...},  // optional
  recommendation: {
    action: "Hire 2 new drivers...",
    watch: "Tuesday/Thursday delivery times...",
    trigger: "If daily orders drop below 65..."
  },
  meta: {
    tier: 1,  // or 2 if data was uploaded
    confidenceBand: "wide"  // or "narrow" for tier 2
  }
};
```

Opus 4.6 generates this data object based on the conversation. The template consumes it.

**Step 11: Test the complete dashboard**

Create a hardcoded test version with the delivery company scenario data. Open in browser. Verify:
- Causal graph renders with nodes and edges
- Monte Carlo animation plays and forms distributions
- Scenario comparison shows 3 distributions
- Taleb badges display correct classifications
- Tornado diagram ranks variables
- Sliders re-run simulation on drag
- Recommendation panel is populated
- Dark mode looks cinematic, not janky

**Step 12: Commit**

```bash
git add templates/
git commit -m "feat: complete dashboard template â€” causal graph, Monte Carlo viz, Taleb badges, sensitivity, sliders, recommendations"
```

---

## Task 6: Create Sample Datasets (`data/`)

**Files:**
- Create: `data/delivery_logs_q4.csv`
- Create: `data/driver_performance.csv`
- Create: `data/generate_sample_data.py`

**Step 1: Write Python script to generate realistic sample data**

`generate_sample_data.py` creates both CSVs with embedded hidden patterns:

**delivery_logs_q4.csv** (~5,000 rows):
- Dates: Oct 1 2025 - Jan 31 2026 (~120 days)
- 5 drivers (D1-D5)
- Tuesday/Thursday have 30-40% more orders
- D2 degrades after Dec 1 (route change)
- D4 gradually declines (burnout)
- D3 (Lisa) consistently high but hours increasing
- Cost per delivery: â‚¬2.80 Mon/Wed, â‚¬4.10 Tue/Thu

**driver_performance.csv** (~600 rows):
- Same date range, one row per driver per day worked
- D2: clear breakpoint Dec 1
- D4: declining deliveries_completed/hour trend
- D3: overtime_hours trending up
- D1, D5: stable
- Correlation: when D2/D4 miss, D3's overtime spikes next day

**Step 2: Run the script and verify**

```bash
cd /Users/muzaffer/projects/ClaudeCode_Hackathon
python data/generate_sample_data.py
```

Verify: open CSVs, spot-check patterns are present, row counts are correct.

**Step 3: Commit**

```bash
git add data/
git commit -m "feat: sample delivery datasets with embedded patterns for demo"
```

---

## Task 7: Build Tier 2 Data Processing (`engines/analyze_data.py`)

**Files:**
- Create: `engines/analyze_data.py`

**Step 1: Write Python analysis script**

This script is what Claude Code runs when the user drops CSV files. It:

1. Reads CSV files from provided paths
2. Extracts distributions for key variables (mean, std, min, max, percentiles, by day-of-week)
3. Finds correlations between variables
4. Detects anomalies and breakpoints (sudden changes in trends)
5. Outputs a JSON summary that Opus 4.6 uses to regenerate the dashboard with sharper data

```python
#!/usr/bin/env python3
"""Prisma Tier 2 â€” Data Analysis Engine"""
import pandas as pd
import numpy as np
import json
import sys

def analyze_delivery_logs(filepath):
    """Extract distributions and patterns from delivery logs."""
    # Parse, compute stats per variable, find day-of-week patterns
    # Detect breakpoints (rolling mean shifts)
    # Return structured dict

def analyze_driver_performance(filepath):
    """Extract driver-level patterns and correlations."""
    # Compute per-driver stats
    # Find trends (linear regression slope per driver)
    # Find correlations (when X is bad, Y gets worse next day)
    # Return structured dict

def cross_reference(delivery_data, driver_data):
    """Find patterns across both datasets."""
    # Match delivery problems to driver issues
    # Find hidden insights
    # Return discoveries list

def main(filepaths):
    results = {}
    discoveries = []
    # Process each file based on detected type
    # Cross-reference if multiple files
    # Output JSON to stdout
    print(json.dumps({"distributions": results, "discoveries": discoveries}, indent=2))

if __name__ == "__main__":
    main(sys.argv[1:])
```

**Step 2: Test with sample data**

```bash
python engines/analyze_data.py data/delivery_logs_q4.csv data/driver_performance.csv
```

Verify: JSON output contains correct distributions, discovers the embedded patterns (Tue/Thu peaks, D2 breakpoint, D3 burnout risk, D4 decline).

**Step 3: Commit**

```bash
git add engines/analyze_data.py
git commit -m "feat: Tier 2 data analysis â€” distribution extraction + pattern discovery"
```

---

## Task 8: Create Example Output (`examples/delivery-company/`)

**Files:**
- Create: `examples/delivery-company/prisma-output.html`

**Step 1: Generate a complete example dashboard**

Take the dashboard template, fill it with the delivery company scenario data (hardcoded `PRISMA_DATA`), and save as a working example. This serves two purposes:
1. Judges can open it immediately without running Claude Code
2. It's our reference implementation for testing

Use the Tier 1 scenario data (estimated from conversation, not from CSV analysis).

**Step 2: Verify it works standalone**

Open `examples/delivery-company/prisma-output.html` in a browser. Everything should work â€” animation, sliders, charts.

**Step 3: Commit**

```bash
git add examples/
git commit -m "feat: example output â€” delivery company decision dashboard"
```

---

## Task 9: Wire Claude Code Integration (Skills + CLAUDE.md refinement)

**Files:**
- Create: `skills/prisma.md`
- Modify: `CLAUDE.md` (refine based on what we learned building the engines)

**Step 1: Create the Prisma skill definition**

`skills/prisma.md` â€” a Claude Code skill that users can invoke:

```markdown
---
name: prisma
description: Run Prisma decision analysis â€” simulate the consequences of a decision
---

# Prisma Decision Analysis

Follow the Prisma workflow defined in CLAUDE.md:

1. Ask "What decision are you facing?"
2. Extract variables with 3-5 follow-up questions
3. Build the causal graph
4. Define scenarios (always include "do nothing")
5. Generate the PRISMA_DATA object
6. Read the dashboard template from templates/dashboard.html
7. Inject PRISMA_DATA into the template
8. Save as output/prisma-dashboard.html
9. Open in the user's browser
```

**Step 2: Refine CLAUDE.md**

Update CLAUDE.md with any learnings from the build â€” exact file paths, exact data format that the template expects, any edge cases discovered.

**Step 3: Test the full flow**

Open Claude Code in the project folder. Type a decision scenario. Verify:
1. Prisma asks good follow-up questions
2. It generates the PRISMA_DATA correctly
3. It produces a working HTML dashboard
4. The dashboard opens in the browser
5. All visualizations work

**Step 4: Commit**

```bash
git add skills/ CLAUDE.md
git commit -m "feat: Claude Code integration â€” Prisma skill + refined CLAUDE.md"
```

---

## Task 10: Push to GitHub + Final README

**Files:**
- Modify: `README.md` (expand with full documentation)

**Step 1: Create GitHub repo**

```bash
gh repo create prisma --public --description "1,000 futures. One decision. Decision intelligence powered by Monte Carlo, Markov chains, and the Taleb framework." --source . --push
```

**Step 2: Expand README.md**

Add:
- Demo GIF/screenshot (from the example output)
- Detailed "How It Works" section with the crew
- Installation instructions
- Example usage
- Architecture diagram (text-based)
- The three tiers explained
- Credits and hackathon context

**Step 3: Push**

```bash
git add -A
git commit -m "docs: complete README with architecture, usage, and examples"
git push
```

---

## v0 Definition of Done

When these tasks are complete, v0 is done:

- [ ] GitHub repo is public with MIT license
- [ ] `claude` in the project folder â†’ Prisma starts asking about decisions
- [ ] Conversation â†’ PRISMA_DATA â†’ HTML dashboard generated and opens in browser
- [ ] Dashboard shows: causal graph, Monte Carlo animation, scenario comparison, Taleb badges, sensitivity tornado, sliders, recommendation panel
- [ ] Sliders re-run simulation in real-time
- [ ] Sample datasets exist and can be dropped for Tier 2 analysis
- [ ] Python analysis script processes CSVs and extracts patterns
- [ ] Example output works standalone in browser
- [ ] Markov timeline shows diverging futures (P3 â€” cut if time)
- [ ] Dark mode cinematic visual style throughout

---

## After v0: Polish Priorities

Once v0 runs end-to-end, iterate on:
1. **Animation quality** â€” smoother dots, better timing, transitions
2. **Tier 2 flow** â€” seamless CSV drop â†’ regeneration experience
3. **Discovery moment** â€” make the hidden insight reveal feel dramatic
4. **Edge cases** â€” different numbers of scenarios, missing data, unusual ranges
5. **Demo rehearsal** â€” practice the 3-minute flow, find rough spots
6. **Demo recording** â€” OBS + face cam, record final video

---

*Plan created: February 11, 2026*
*"One decision enters. A thousand futures come out."*
